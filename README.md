<h3 align="center">
Hands-On Triton Tutorial ğŸ“–
</h3>

<h4 align="center">
Learn Triton: No GPU Experience Required
</h4>

<p align="center">
<a href="https://tt-tut.top"><b>ğŸ”— tt-tut.top</b></a>
</p>

<p align="center">
<a href="README.en.md"><b>English</b></a> | <a><b>ä¸­æ–‡</b></a>
</p>

æœ¬æ•™ç¨‹é¢å‘æ²¡æœ‰ GPU ç»éªŒçš„çš„Tritonåˆå­¦è€…ï¼Œå¸¦ä½ ä»åŸºç¡€çš„å‘é‡åŠ åˆ°RoPEã€matmul_ogsã€topkã€Gluon Attention
ç­‰å¤§æ¨¡å‹ç®—å­è¿›é˜¶å­¦ä¹ ä¹‹è·¯ã€‚å¦‚æœæ²¡æœ‰PythonåŸºç¡€ï¼Œå¯ä»¥é€šè¿‡[Pythonç¼–ç¨‹å…¥é—¨æ•™ç¨‹(ä»¥åœ¨çº¿è¯„æµ‹å¹³å°ä¸ºè½½ä½“)](https://www.cnblogs.com/BobHuang/p/14341687.html)æ¥å­¦ä¹  Python è¯­æ³•ï¼Œæˆ–è€…æ ¹æ®æœ¬æ•™ç¨‹å†…å®¹ä¸ ChatGPT å¯¹è¯ç›´æ¥å…¥é—¨ Tritonã€‚

ä½œè€…ï¼š[BobHuang](https://github.com/sBobHuang) - [OpenMLIR](https://mlir.top)

ä½œè€…é‚®ç®±ï¼štt@bobhuang.xyz

<!-- vscode-markdown-toc -->
* ä¸€ã€ [Triton ç®€ä»‹](#Triton-ç®€ä»‹)
* äºŒã€ [å‘é‡åŠ ç®—å­å®æˆ˜](#å‘é‡åŠ ç®—å­å®æˆ˜)
 * 2.1 torchçš„å‘é‡åŠ æ³•
 * 2.2 å•program 16ä¸ªå…ƒç´ åŠ æ³•å’ŒéªŒè¯
 * 2.3 é€šè¿‡maskæ§åˆ¶å…ƒç´ è®¿é—®
 * 2.4 å¤šBlock(program)è¿è¡Œ
<!-- vscode-markdown-toc-config
	numbering=true
	autoSave=true
	/vscode-markdown-toc-config -->
<!-- /vscode-markdown-toc -->

##  ä¸€ã€ <a name='Triton-ç®€ä»‹'></a>Triton-ç®€ä»‹

[OpenAI/Triton](https://github.com/openai/triton) æ˜¯ä¸€ä¸ªè®©ä½ ç”¨ Python å†™é«˜æ€§èƒ½ GPU ç®—å­çš„ç¼–ç¨‹è¯­è¨€(DSL)ã€‚ç›®å‰æœ‰[NVIDIA](https://github.com/triton-lang/triton/tree/main/third_party/nvidia)ã€[AMD](https://github.com/triton-lang/triton/tree/main/third_party/amd)ã€[åä¸ºæ˜‡è…¾](https://github.com/Ascend/triton-ascend)ã€[å¯’æ­¦çºª](https://github.com/FlagTree/flagtree/tree/main/third_party/cambricon)ã€[æ‘©å°”çº¿ç¨‹](https://github.com/FlagTree/flagtree/tree/main/third_party/mthreads)ã€[æ²æ›¦](https://github.com/FlagTree/flagtree/tree/main/third_party/metax)ç­‰å¤šä¸ªåç«¯ï¼Œä¸€ä¸ªkernel**å¤šç§ç¡¬ä»¶**å‡å¯ä»¥è¿è¡Œï¼Œå…·ä½“è§[FlagOpen/FlagGems](https://github.com/FlagOpen/FlagGems)ã€‚

ä¼˜åŠ¿ï¼šå†™æ³•åƒ NumPyï¼Œè½»æ¾åˆ©ç”¨ GPU å¹¶è¡Œå’Œä¼˜åŒ–ç‰¹æ€§ã€‚

åº”ç”¨ï¼šåŠ é€Ÿæ·±åº¦å­¦ä¹ ç®—å­å’Œè‡ªå®šä¹‰ç®—å­ï¼Œæå‡å¤§æ¨¡å‹è®­ç»ƒå’Œæ¨ç†æ€§èƒ½ã€‚

##  äºŒã€ <a name='å‘é‡åŠ ç®—å­å®æˆ˜'></a>å‘é‡åŠ ç®—å­å®æˆ˜

æœ¬æ•™ç¨‹ä½¿ç”¨ Triton 3.4.0(released on 2025, Jul 31)ï¼Œåªéœ€å®‰è£… torch==2.8.0ã€‚è‹¥ä½¿ç”¨è¾ƒä½ç‰ˆæœ¬çš„ PyTorchï¼Œå¯è‡ªè¡Œå‡çº§ Tritonç‰ˆæœ¬ã€‚Tritonå…·æœ‰å¾ˆå¥½çš„ç‰ˆæœ¬å…¼å®¹ï¼Œå¤§éƒ¨åˆ†ç®—å­å¯¹Tritonç‰ˆæœ¬**æ²¡æœ‰è¦æ±‚**ã€‚

å…¥é—¨å…ˆå­¦ a + bï¼Œå‘é‡åŠ æ³•å¯ä»¥è¡¨ç¤ºä¸º å‘é‡c = å‘é‡a + å‘é‡bï¼Œå³æŠŠ a å’Œ b ä¸­å¯¹åº”ä½ç½®çš„æ¯ä¸ªæ•°å­—ç›¸åŠ ã€‚

### 2.1 torchçš„å‘é‡åŠ æ³•

æˆ‘ä»¬å…ˆç”¨Pytorchæ¥å®ç°ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ torch.randn æ¥ç”Ÿæˆéšæœºçš„å‘é‡aã€bï¼Œåœ¨torché‡Œç›´æ¥ç›¸åŠ å°±å¯ä»¥ã€‚

```Python
import torch

if __name__ == "__main__":
    N = 16
    a = torch.randn(N, device='cuda')
    b = torch.randn(N, device='cuda')
    c = a + b
    print(a, b, c, sep="\n")
```

å¯ä»¥å¾—åˆ°å¦‚ä¸‹è¾“å‡ºç»“æœï¼Œç¬¬ä¸‰ä¸ªtensorçš„å€¼æ˜¯å‰ä¸¤ä¸ªtensorå¯¹åº”ä½ç½®ç›¸åŠ ã€‚ç”±äºæ˜¯éšæœºæ•°æ®ï¼Œæ‰€ä»¥ä»¥ä¸‹è¾“å‡ºç»“æœä¼šå˜åŒ–ã€‚

```
tensor([-0.3947,  0.1963,  0.4782, -0.0215,  1.5055,  0.1066, -0.8224,  0.0999,
        -0.1316,  0.3244, -1.6962, -0.1411,  0.5005,  0.0396,  0.4774,  0.9639],
       device='cuda:0')
tensor([-0.1621, -1.0437,  0.5023,  0.3897,  0.6714, -0.8212, -0.2596, -0.3467,
        -2.2264,  0.7489,  1.3961, -2.1076,  0.0119, -0.8835, -0.4079,  1.8599],
       device='cuda:0')
tensor([-0.5568, -0.8474,  0.9805,  0.3682,  2.1769, -0.7145, -1.0820, -0.2469,
        -2.3581,  1.0732, -0.3000, -2.2486,  0.5124, -0.8439,  0.0695,  2.8238],
       device='cuda:0')
```

Pytorchæ˜¯é€šè¿‡è°ƒç”¨äº†atençš„[aten/src/ATen/native/cuda/CUDALoops.cuh:L334](https://github.com/pytorch/pytorch/blob/ba56102387ef21a3b04b357e5b183d48f0afefc7/aten/src/ATen/native/cuda/CUDALoops.cuh#L334) çš„ `vectorized_elementwise_kernel` CUDA kernelæ¥å®Œæˆè®¡ç®—çš„ã€‚

### 2.2 å•program 16ä¸ªå…ƒç´ åŠ æ³•å’ŒéªŒè¯

æˆ‘ä»¬æ¥å†™æˆ‘ä»¬çš„Triton kernelã€‚

æˆ‘ä»¬å…ˆè€ƒè™‘åœ¨1ä¸ªprogramå†…åšå®Œï¼Œä¹Ÿå°±æ˜¯1ä¸ªBlockè¦å®Œæˆ16ä¸ªå…ƒç´ çš„è®¡ç®—ã€‚Tritonçš„æºç éœ€è¦ä½¿ç”¨@triton.jitè£…é¥°å™¨ï¼Œç”¨æ¥æ ‡è®°è¿™æ˜¯ä¸€æ®µTriton kernelå‡½æ•°ï¼Œä½¿å…¶èƒ½å¤Ÿè¢«JITï¼ˆå³æ—¶ç¼–è¯‘ï¼‰ç¼–è¯‘å¹¶åœ¨GPUä¸Šè¿è¡Œã€‚ç„¶åæˆ‘ä»¬å°†tensoråšä¸ºå‚æ•°ï¼Œå®é™…ä¸Šä¼ é€’ä¸‹å»çš„æ˜¯tensorçš„data_ptr()ä¹Ÿå°±æ˜¯æŒ‡é’ˆã€‚ç©ºkernelä»£ç å¦‚ä¸‹æ‰€ç¤º

```Python
@triton.jit
def vector_add_kernel(a_ptr, b_ptr, c_ptr):
    pass

def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):
    grid = (1,)
    vector_add_kernel[grid](a, b, c)
```

kernelå†…æˆ‘ä»¬éœ€è¦å–å‡º16ä¸ªå…ƒç´ ï¼Œå¯¹åº”ä½ç½®å…ƒç´ ç›¸åŠ åå­˜èµ·æ¥å³å¯ã€‚å¯ä»¥ä½¿ç”¨`tl.arange`ç”Ÿæˆè¿ç»­ç´¢å¼•`[0, 1, ..., 16)`ï¼Œé‚£ä¹ˆaçš„æŒ‡é’ˆå°±å¯ä»¥ç”¨`a_ptr + offsets`è¡¨è¾¾ï¼Œç„¶åä½¿ç”¨`tl.load`å–å‡ºå…ƒç´ å†…å®¹ã€‚åœ¨åˆ†åˆ«å–å‡ºaå’Œbåå¯¹ä¸¤è€…è¿›è¡Œç›¸åŠ ï¼Œæœ€åä½¿ç”¨`tl.store`å¯¹ç»“æœè¿›è¡Œå­˜å‚¨ï¼Œkernelä»£ç å¦‚ä¸‹æ‰€ç¤ºã€‚

```Python
import triton
import triton.language as tl

@triton.jit
def vector_add_kernel(a_ptr, b_ptr, c_ptr):
    # ç”Ÿæˆè¿ç»­ç´¢å¼• [0, 1, ..., 15]ï¼Œç”¨äºè®¿é—® 16 ä¸ªå…ƒç´ 
    offsets = tl.arange(0, 16)
    # æ ¹æ®ç´¢å¼•ä» a_ptr æŒ‡å‘çš„åœ°å€åŠ è½½ 16 ä¸ªå…ƒç´ 
    a = tl.load(a_ptr + offsets)
    # æ ¹æ®ç´¢å¼•ä» b_ptr æŒ‡å‘çš„åœ°å€åŠ è½½ 16 ä¸ªå…ƒç´ 
    b = tl.load(b_ptr + offsets)
    # å¯¹åº”ä½ç½®å…ƒç´ ç›¸åŠ 
    c = a + b
    # å°†ç»“æœå†™å›åˆ° c_ptr æŒ‡å‘çš„åœ°å€
    tl.store(c_ptr + offsets, c)
```

æˆ‘ä»¬æ¥ä¸‹æ¥éªŒè¯ä¸‹è¿™ä¸ªkernelï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`torch.empty_like`æ¥äº§ç”Ÿ`triton_output`ï¼Œç„¶åè°ƒç”¨`solve`å³å¯ã€‚

```Python
    triton_output = torch.empty_like(a)
    solve(a, b , triton_output, N)
```

å¯¹æ¯”ç­”æ¡ˆå¯ä»¥ä½¿ç”¨`torch.testing.assert_close`ï¼Œæ‰€ä»¥æ•´ä¸ªPythonç¨‹åºå¦‚ä¸‹æ‰€ç¤º

```Python
import torch
import triton
import triton.language as tl

@triton.jit
def vector_add_kernel(a_ptr, b_ptr, c_ptr):
    offsets = tl.arange(0, 16)
    a = tl.load(a_ptr + offsets)
    b = tl.load(b_ptr + offsets)
    c = a + b
    tl.store(c_ptr + offsets, c)

def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):
    grid = (1,)
    vector_add_kernel[grid](a, b, c)

if __name__ == "__main__":
    N = 16
    a = torch.randn(N, device='cuda')
    b = torch.randn(N, device='cuda')
    torch_output = a + b
    triton_output = torch.empty_like(a)
    solve(a, b , triton_output, N)
    if torch.allclose(triton_output, torch_output):
        print("âœ… Triton and Torch match")
    else:
        print("âŒ Triton and Torch differ")
```

è¿è¡Œä¸Šè¿°ç¨‹åºä½ ä¼šå¾—åˆ°`âœ… Triton and Torch match`ï¼Œä»£è¡¨å¯ä»¥å¯¹ä¸Šç­”æ¡ˆã€‚

### 2.3 é€šè¿‡maskæ§åˆ¶å…ƒç´ è®¿é—®

å¦‚æœè¾“å…¥æ˜¯15ä¸ªå…ƒç´ å‘¢ï¼Œæ˜¯ä¸æ˜¯ä½¿ç”¨`offsets = tl.arange(0, 15)`å°±èƒ½è§£å†³é—®é¢˜å‘¢ï¼Œè¿è¡Œä½ ä¼šå¾—åˆ°`ValueError: arange's range must be a power of 2`ï¼Œè¿™æ˜¯Tritonæœ¬èº«çš„é™åˆ¶ï¼Œå› ä¸ºæˆ‘ä»¬çš„`Block`(program, çº¿ç¨‹å—)å¤„ç†çš„æ•°æ®é‡é€šå¸¸æ˜¯ 2 çš„å¹‚ã€‚ä¸ºäº†é¿å…è®¿é—®è¶Šç•Œï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨maskã€‚

maskæ˜¯`tl.load`å’Œ`tl.store`çš„ä¸€ä¸ªå‚æ•°ï¼Œæˆ‘ä»¬è®¡ç®—maskä¹Ÿæ˜¯å°†`tl.arange`çš„è¿ç»­ç´¢å¼•ä¸`15`å¯¹æ¯”å³å¯ã€‚

```Python
@triton.jit
def vector_add_kernel(a_ptr, b_ptr, c_ptr):
    offsets = tl.arange(0, 16)
    # è®¡ç®— maskï¼šåªå¤„ç† offsets < 15 çš„ä½ç½®
    mask = offsets < 15
    a = tl.load(a_ptr + offsets, mask=mask)
    b = tl.load(b_ptr + offsets, mask=mask)
    c = a + b
    tl.store(c_ptr + offsets, c, mask=mask)
```

å…ƒç´ ä¸ªæ•°ä¸ä¸€å®šéƒ½ä¸º15ï¼Œ1~16éƒ½æœ‰å¯èƒ½ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†`N`åšä¸ºå‚æ•°ä¼ å…¥ï¼Œå®Œæ•´ä»£ç å¦‚ä¸‹ã€‚

```Python
import torch
import triton
import triton.language as tl

@triton.jit
def vector_add_kernel(a_ptr, b_ptr, c_ptr, N):
    offsets = tl.arange(0, 16)
    mask = offsets < N
    a = tl.load(a_ptr + offsets, mask=mask)
    b = tl.load(b_ptr + offsets, mask=mask)
    c = a + b
    tl.store(c_ptr + offsets, c, mask=mask)

def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):
    grid = (1,)
    vector_add_kernel[grid](a, b, c, N)

if __name__ == "__main__":
    for N in range(1, 16):
        a = torch.randn(N, device='cuda')
        b = torch.randn(N, device='cuda')
        torch_output = a + b
        triton_output = torch.empty_like(a)
        solve(a, b , triton_output, N)
        if torch.allclose(triton_output, torch_output):
            print("âœ… Triton and Torch match")
        else:
            print("âŒ Triton and Torch differ")
```

è¿è¡Œä»¥ä¸Šç¨‹åºä¼šè¾“å‡º15ä¸ª`âœ… Triton and Torch match`ï¼Œæˆ‘ä»¬çš„ç®—å­é€šè¿‡äº†ç¬¬ä¸€é˜¶æ®µçš„å¥å£®æ€§æ£€æµ‹ã€‚

æˆ‘ä»¬å¯ä»¥å¢åŠ `tl.arange`ä¸­endçš„å€¼ï¼Œæ¥è®©æ›´å¤§Nè¿è¡Œï¼Œä½ å¯ä»¥åŠ¨æ‰‹è¯•è¯•ã€‚

### 2.4 å¤šBlock(program)è¿è¡Œ

`1048576`æ˜¯`tl.arange`çš„æœ€å¤§å€¼ï¼Œæ¯”å¦‚`2097152`å°±ä¼šæŠ¥é”™`ValueError: numel (2097152) exceeds triton maximum tensor numel (1048576)`ï¼ŒTriton é»˜è®¤ å•ä¸ª tensor æœ€å¤šåªèƒ½æœ‰ 2^20 = 1048576 ä¸ªå…ƒç´ ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä½¿ç”¨å¤šä¸ª`Block`ã€‚

`Block`(program,çº¿ç¨‹å—)æ˜¯GPU è½¯ä»¶è°ƒåº¦çš„æœ€å°å¯ç‹¬ç«‹è°ƒåº¦çš„å•ä½ï¼Œæˆ‘ä»¬å½“ç„¶ä¸æ­¢1ä¸ªblockï¼Œä»æ€§èƒ½è§’åº¦ï¼Œæˆ‘ä»¬ä¹Ÿåº”è¯¥ä½¿ç”¨å¤šä¸ªBlockæ¥å®Œæˆä»»åŠ¡ã€‚

Grid æ˜¯ç”±å¤šä¸ª Block ç»„æˆçš„é›†åˆï¼Œä¸€ä¸ª Grid å¯ä»¥æ˜¯ 1Dã€2D æˆ– 3Dã€‚å‘é‡çš„Blockåªåœ¨ x æ–¹å‘æ’åˆ—å°±å¤Ÿäº†ï¼Œkernelå†…æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`tl.program_id(axis=0)` æ¥è·å– block çš„ç¼–å·ã€‚

ç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡Tritonçš„`device_print`å°†`pid`è¾“å‡ºå‡ºæ¥ï¼Œä»¥ä¸‹ä¸ºç¤ºä¾‹ä»£ç ã€‚

```Python
import triton
import triton.language as tl

@triton.jit
def test_pid_kernel():
    pid = tl.program_id(axis=0)
    tl.device_print('pid', pid)

def solve():
    grid = (2,)
    test_pid_kernel[grid]()

if __name__ == "__main__":
    solve()
```

é€šè¿‡è¿è¡Œä»¥ä¸Šä»£ç ï¼Œä½ ä¼šå¾—åˆ°å¾ˆå¤šä¸ª`pid (0, 0, 0) idx () pid: 0`å’Œ`pid (1, 0, 0) idx () pid: 1`ï¼Œå› ä¸ºæ¯ä¸ªçº¿ç¨‹éƒ½æ‰§è¡Œäº†è¾“å‡ºæ“ä½œï¼Œæˆ‘ä»¬Tritonä»£ç å°±æ˜¯é€šè¿‡è¿è¡Œå¤šä¸ªçº¿ç¨‹æ¥å®ŒæˆåŠ é€Ÿçš„ã€‚

é’ˆå¯¹æˆ‘ä»¬çš„ç¨‹åºæˆ‘ä»¬ä¹Ÿæ˜¯è¦ä½¿ç”¨`pid`æ¥æ§åˆ¶åç§»å³å¯ã€‚æˆ‘ä»¬æ¯ä¸ªBlockä¾æ—§åªåš`16`ä¸ªå…ƒç´ ï¼Œéœ€è¦çš„Blockæ•°å°±æ˜¯`ceil(N/16)`ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨`triton.cdiv(N, 16)`æ¥è®¡ç®—ã€‚kernelå†…å»è·å–ç´¢å¼•ï¼Œè®¡ç®—å½“å‰Blockèµ·å§‹ç´¢å¼•ï¼Œç„¶åç”Ÿæˆç”Ÿæˆå½“å‰ block å†…çš„è¿ç»­ç´¢å¼•å³å¯ï¼Œå…¶ä»–å’Œä¹‹å‰éƒ½ä¸€è‡´ã€‚å…¨éƒ¨ä»£ç å¦‚ä¸‹æ‰€ç¤º

```Python
import torch
import triton
import triton.language as tl

@triton.jit
def vector_add_kernel(a_ptr, b_ptr, c_ptr, N):
    # è·å–å½“å‰ program åœ¨ åœ¨ x æ–¹å‘ ä¸­çš„ç´¢å¼•
    pid = tl.program_id(axis=0)
    # è®¡ç®—å½“å‰ block çš„èµ·å§‹å…ƒç´ ç´¢å¼•
    block_start = pid * 16
    # ç”Ÿæˆå½“å‰ block å†…çš„è¿ç»­ç´¢å¼• [block_start, block_start+1, ..., block_start+15]
    offsets = block_start + tl.arange(0, 16)
    mask = offsets < N
    a = tl.load(a_ptr + offsets, mask=mask)
    b = tl.load(b_ptr + offsets, mask=mask)
    c = a + b
    tl.store(c_ptr + offsets, c, mask=mask)

def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):
    grid = (triton.cdiv(N, 16), )
    vector_add_kernel[grid](a, b, c, N)

if __name__ == "__main__":
    N = 12345
    a = torch.randn(N, device='cuda')
    b = torch.randn(N, device='cuda')
    torch_output = a + b
    triton_output = torch.empty_like(a)
    solve(a, b , triton_output, N)
    if torch.allclose(triton_output, torch_output):
        print("âœ… Triton and Torch match")
    else:
        print("âŒ Triton and Torch differ")
```

æˆ‘ä»¬å¯ä»¥ä¿®æ”¹ä»»æ„ N æ¥å®éªŒä¸åŒæƒ…å†µï¼Œè€Œåœ¨çº¿è¯„æµ‹å¹³å°`online judge` å¯ä»¥å¸®ä½ è‡ªåŠ¨éªŒè¯ç»“æœæ˜¯å¦æ­£ç¡®ï¼Œä¹Ÿå°±æ˜¯[LeetGPU](https://leetgpu.com)ã€‚è¿™ä¸ªåœ¨çº¿è¯„æµ‹å¹³å°å¯ä»¥éšæœºç”Ÿæˆæ›´å¤šçš„æ•°æ®å¸®ä½ éªŒè¯ç®—å­æ˜¯å¦æ­£ç¡®ï¼Œå¦å¤–å…¶è¿˜æä¾›äº†`H200`ã€`B200`ç­‰å…ˆè¿›GPUã€‚åœ¨[Vector Addition](https://leetgpu.com/challenges/vector-addition) é€‰æ‹©**Triton**å¹¶æäº¤ä¸Šè¿°é™¤`main`å‡½æ•°çš„ä»£ç ï¼Œä½ ä¼šè·å¾—`Success`ã€‚

![æäº¤åˆ°LeetGPUçš„Vector Addition](pics/submit.png)
