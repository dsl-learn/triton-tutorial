<h3 align="center">
Hands-On Triton Tutorial ğŸ“–
</h3>

<h4 align="center">
Learn Triton: No GPU Experience Required
</h4>

<p align="center">
<a href="https://tt-tut.top"><b>ğŸ”— tt-tut.top</b></a>
</p>

<p align="center">
<a href="README.en.md"><b>English</b></a> | <a><b>ä¸­æ–‡</b></a>
</p>

æœ¬æ•™ç¨‹é¢å‘æ²¡æœ‰ GPU ç»éªŒçš„çš„Tritonåˆå­¦è€…ï¼Œå¸¦ä½ ä»åŸºç¡€çš„å‘é‡åŠ åˆ°RoPEã€matmul_ogsã€topkã€Gluon Attention
ç­‰å¤§æ¨¡å‹ç®—å­è¿›é˜¶å­¦ä¹ ä¹‹è·¯ã€‚å¦‚æœæ²¡æœ‰PythonåŸºç¡€ï¼Œå¯ä»¥é€šè¿‡[Pythonç¼–ç¨‹å…¥é—¨æ•™ç¨‹(ä»¥åœ¨çº¿è¯„æµ‹å¹³å°ä¸ºè½½ä½“)](https://www.cnblogs.com/BobHuang/p/14341687.html)æ¥å­¦ä¹  Python è¯­æ³•ï¼Œæˆ–è€…æ ¹æ®æœ¬æ•™ç¨‹å†…å®¹ä¸ ChatGPT å¯¹è¯ç›´æ¥å…¥é—¨ Tritonã€‚

ä½œè€…ï¼š[BobHuang](https://github.com/sBobHuang) - [OpenMLIR](https://mlir.top)

ä½œè€…é‚®ç®±ï¼štt@bobhuang.xyz

* ä¸€ã€ [Triton ç®€ä»‹](#Triton-ç®€ä»‹)

* äºŒã€ [å‘é‡åŠ ç®—å­å®æˆ˜](#å‘é‡åŠ ç®—å­å®æˆ˜)

##  ä¸€ã€ <a name='Triton-ç®€ä»‹'></a>Triton-ç®€ä»‹

[OpenAI/Triton](https://github.com/openai/triton) æ˜¯ä¸€ä¸ªè®©ä½ ç”¨ Python å†™é«˜æ€§èƒ½ GPU ç®—å­çš„ç¼–ç¨‹è¯­è¨€(DSL)ã€‚ç›®å‰æœ‰[NVIDIA](https://github.com/triton-lang/triton/tree/main/third_party/nvidia)ã€[AMD](https://github.com/triton-lang/triton/tree/main/third_party/amd)ã€[åä¸ºæ˜‡è…¾](https://github.com/Ascend/triton-ascend)ã€[å¯’æ­¦çºª](https://github.com/FlagTree/flagtree/tree/main/third_party/cambricon)ã€[æ‘©å°”çº¿ç¨‹](https://github.com/FlagTree/flagtree/tree/main/third_party/mthreads)ã€[æ²æ›¦](https://github.com/FlagTree/flagtree/tree/main/third_party/metax)ç­‰å¤šä¸ªåç«¯ï¼Œä¸€ä¸ªkernel**å¤šç§ç¡¬ä»¶**å‡å¯ä»¥è¿è¡Œï¼Œå…·ä½“è§[FlagOpen/FlagGems](https://github.com/FlagOpen/FlagGems)ã€‚

ä¼˜åŠ¿ï¼šå†™æ³•åƒ NumPyï¼Œè½»æ¾åˆ©ç”¨ GPU å¹¶è¡Œå’Œä¼˜åŒ–ç‰¹æ€§ã€‚

åº”ç”¨ï¼šåŠ é€Ÿæ·±åº¦å­¦ä¹ ç®—å­å’Œè‡ªå®šä¹‰ç®—å­ï¼Œæå‡å¤§æ¨¡å‹è®­ç»ƒå’Œæ¨ç†æ€§èƒ½ã€‚

##  äºŒã€ <a name='å‘é‡åŠ ç®—å­å®æˆ˜'></a>å‘é‡åŠ ç®—å­å®æˆ˜

æœ¬æ•™ç¨‹ä½¿ç”¨ Triton 3.4.0(released on 2025, Jul 31)ï¼Œåªéœ€å®‰è£… torch==2.8.0ã€‚è‹¥ä½¿ç”¨è¾ƒä½ç‰ˆæœ¬çš„ PyTorchï¼Œå¯è‡ªè¡Œå‡çº§ Tritonç‰ˆæœ¬ã€‚Tritonå…·æœ‰å¾ˆå¥½çš„ç‰ˆæœ¬å…¼å®¹ï¼Œå¤§éƒ¨åˆ†ç®—å­å¯¹Tritonç‰ˆæœ¬**æ²¡æœ‰è¦æ±‚**ã€‚

å…¥é—¨å…ˆå­¦ a + bï¼Œå‘é‡åŠ æ³•å¯ä»¥è¡¨ç¤ºä¸º å‘é‡c = å‘é‡a + å‘é‡bï¼Œå³æŠŠ a å’Œ b ä¸­å¯¹åº”ä½ç½®çš„æ¯ä¸ªæ•°å­—ç›¸åŠ ã€‚

æˆ‘ä»¬å…ˆç”¨Pytorchæ¥å®ç°ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ torch.randn æ¥ç”Ÿæˆéšæœºçš„å‘é‡aã€bï¼Œåœ¨torché‡Œç›´æ¥ç›¸åŠ å°±å¯ä»¥ã€‚

```Python
import torch

if __name__ == "__main__":
    N = 16
    a = torch.randn(N, device='cuda')
    b = torch.randn(N, device='cuda')
    c = a + b
    print(a, b, c, sep="\n")
```

å¯ä»¥å¾—åˆ°å¦‚ä¸‹è¾“å‡ºç»“æœï¼Œç¬¬ä¸‰ä¸ªtensorçš„å€¼æ˜¯å‰ä¸¤ä¸ªtensorå¯¹åº”ä½ç½®ç›¸åŠ ã€‚ç”±äºæ˜¯éšæœºæ•°æ®ï¼Œæ‰€ä»¥ä»¥ä¸‹è¾“å‡ºç»“æœä¼šå˜åŒ–ã€‚

```
tensor([-0.3947,  0.1963,  0.4782, -0.0215,  1.5055,  0.1066, -0.8224,  0.0999,
        -0.1316,  0.3244, -1.6962, -0.1411,  0.5005,  0.0396,  0.4774,  0.9639],
       device='cuda:0')
tensor([-0.1621, -1.0437,  0.5023,  0.3897,  0.6714, -0.8212, -0.2596, -0.3467,
        -2.2264,  0.7489,  1.3961, -2.1076,  0.0119, -0.8835, -0.4079,  1.8599],
       device='cuda:0')
tensor([-0.5568, -0.8474,  0.9805,  0.3682,  2.1769, -0.7145, -1.0820, -0.2469,
        -2.3581,  1.0732, -0.3000, -2.2486,  0.5124, -0.8439,  0.0695,  2.8238],
       device='cuda:0')
```

Pytorchçš„æ˜¯é€šè¿‡è°ƒç”¨äº†atençš„[aten/src/ATen/native/cuda/CUDALoops.cuh:L334](https://github.com/pytorch/pytorch/blob/ba56102387ef21a3b04b357e5b183d48f0afefc7/aten/src/ATen/native/cuda/CUDALoops.cuh#L334) çš„CUDA kernelæ¥å®Œæˆè®¡ç®—çš„ã€‚æˆ‘ä»¬æ¥å†™æˆ‘ä»¬çš„Triton kernelã€‚

æˆ‘ä»¬å…ˆè€ƒè™‘åœ¨1ä¸ªprogramå†…åšå®Œï¼Œä¹Ÿå°±æ˜¯1ä¸ªBlockè¦å®Œæˆ16ä¸ªå…ƒç´ çš„è®¡ç®—ã€‚Tritonçš„æºç éœ€è¦ä½¿ç”¨@triton.jitè£…é¥°å™¨ï¼Œç”¨æ¥æ ‡è®°è¿™æ˜¯ä¸€æ®µTriton kernelå‡½æ•°ï¼Œä½¿å…¶èƒ½å¤Ÿè¢«JITï¼ˆå³æ—¶ç¼–è¯‘ï¼‰ç¼–è¯‘å¹¶åœ¨GPUä¸Šè¿è¡Œã€‚ç„¶åæˆ‘ä»¬å°†tensoråšä¸ºå‚æ•°ï¼Œå®é™…ä¸Šä¼ é€’ä¸‹å»çš„æ˜¯tensorçš„data_ptr()ä¹Ÿå°±æ˜¯æŒ‡é’ˆã€‚ç©ºkernelä»£ç å¦‚ä¸‹æ‰€ç¤º

```Python
@triton.jit
def vector_add_kernel(a_ptr, b_ptr, c_ptr):
    pass

def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):
    grid = (1,)
    vector_add_kernel[grid](a, b, c)
```

kernelå†…æˆ‘ä»¬éœ€è¦å–å‡º16ä¸ªå…ƒç´ ï¼Œéœ€è¦ä½¿ç”¨`tl.arange`ç”Ÿæˆè¿ç»­ç´¢å¼•`[0, 1, ..., 16)`ï¼Œç„¶åä½¿ç”¨`tl.load`å–å‡ºå…ƒç´ å†…å®¹ã€‚åˆ†åˆ«å–å‡ºaå’Œbåå¯¹ä¸¤è€…è¿›è¡Œç›¸åŠ ã€‚ç„¶åä½¿ç”¨`tl.store`å¯¹ç»“æœè¿›è¡Œå­˜å‚¨ï¼Œkernelä»£ç å¦‚ä¸‹æ‰€ç¤ºã€‚

```Python
import triton
import triton.language as tl

@triton.jit
def vector_add_kernel(a_ptr, b_ptr, c_ptr):
    offsets = tl.arange(0, 16)
    a = tl.load(a_ptr + offsets)
    b = tl.load(b_ptr + offsets)
    c = a + b
    tl.store(c_ptr + offsets, c)
```
