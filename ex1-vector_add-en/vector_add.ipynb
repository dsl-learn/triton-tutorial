{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOneuniVD62RA+3s4eS4edo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import random\n","random.seed(42)\n","\n","N = 16\n","a = torch.randn(N, device='cuda')\n","b = torch.randn(N, device='cuda')\n","c = a + b\n","print(a, b, c, sep=\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CaKlUGln2LlC","executionInfo":{"status":"ok","timestamp":1760682361402,"user_tz":300,"elapsed":303,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}},"outputId":"5906b8f6-82e2-45e7-a780-e3291159483d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.3327, -0.3802,  0.0867,  0.1939,  0.4104, -0.9106, -1.0601, -0.1699,\n","         0.4178, -1.8070, -1.0283,  0.2256,  0.2209, -1.0756,  0.1709, -0.6684],\n","       device='cuda:0')\n","tensor([ 0.7863,  0.1051,  0.0466, -0.1470,  1.3219,  0.5543, -0.5274,  0.7996,\n","         1.1139, -0.1291, -1.2053,  1.1623, -1.4873, -0.4576,  1.1796, -0.7119],\n","       device='cuda:0')\n","tensor([ 0.4535, -0.2751,  0.1332,  0.0469,  1.7324, -0.3563, -1.5874,  0.6298,\n","         1.5317, -1.9362, -2.2336,  1.3879, -1.2665, -1.5332,  1.3505, -1.3803],\n","       device='cuda:0')\n"]}]},{"cell_type":"code","source":["print(a.data_ptr())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHGOCT9L2MAK","executionInfo":{"status":"ok","timestamp":1760682371249,"user_tz":300,"elapsed":2,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}},"outputId":"67fc2afd-8e48-43e1-eb9c-39481bec0012"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["140081249648640\n"]}]},{"cell_type":"code","source":["import triton\n","import triton.language as tl\n","\n","@triton.jit\n","def vector_add_kernel(a_ptr, b_ptr, c_ptr):\n","    pass\n","\n","def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):\n","    grid = (1,) # `1` denotes the number of blocks we used, for a 16-element vector, 1 is more than enough\n","    vector_add_kernel[grid](a, b, c)"],"metadata":{"id":"d_Wq420w2Oe1","executionInfo":{"status":"ok","timestamp":1760682384281,"user_tz":300,"elapsed":42,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import triton\n","import triton.language as tl\n","\n","@triton.jit\n","def vector_add_kernel(a_ptr, b_ptr, c_ptr):\n","    offsets = tl.arange(0, 16) # generates indexes [0, 1, ..., 15] for 16 elements\n","\n","    a = tl.load(a_ptr + offsets) # load values from memory with their indexes, variable `a` is a Triton tensor, more specifically, the datatype of `a` is tl.tensor(float32, (16,))\n","    b = tl.load(b_ptr + offsets)\n","\n","    c = a + b # element wise addition\n","\n","    tl.store(c_ptr + offsets, c)"],"metadata":{"id":"MPgS9tkV2RKj","executionInfo":{"status":"ok","timestamp":1760682405035,"user_tz":300,"elapsed":3,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import torch\n","import triton\n","import triton.language as tl\n","\n","@triton.jit\n","def vector_add_kernel(a_ptr, b_ptr, c_ptr):\n","    offsets = tl.arange(0, 16)\n","    a = tl.load(a_ptr + offsets)\n","    b = tl.load(b_ptr + offsets)\n","    c = a + b\n","    tl.store(c_ptr + offsets, c)\n","\n","def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):\n","    grid = (1,)\n","    vector_add_kernel[grid](a, b, c)\n","\n","if __name__ == \"__main__\":\n","    N = 16\n","    a = torch.randn(N, device='cuda')\n","    b = torch.randn(N, device='cuda')\n","    torch_output = a + b\n","    triton_output = torch.empty_like(a)\n","    solve(a, b , triton_output, N)\n","    if torch.allclose(triton_output, torch_output):\n","        print(\"✅ Triton and Torch match\")\n","    else:\n","        print(\"❌ Triton and Torch differ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyG3CbRq2U_D","executionInfo":{"status":"ok","timestamp":1760682424004,"user_tz":300,"elapsed":398,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}},"outputId":"25fd6395-cd87-4654-b632-2e2360775993"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Triton and Torch match\n"]}]},{"cell_type":"code","source":["\"\"\" WARNING: FOLLOWING CODE SAMPLE DEMONSTRATES A WRONG PATTERN\"\"\"\n","import torch\n","import triton\n","import triton.language as tl\n","\n","@triton.jit\n","def vector_add_kernel(a_ptr, b_ptr, c_ptr):\n","    offsets = tl.arange(0, 16)\n","    a = tl.load(a_ptr + offsets)\n","    b = tl.load(b_ptr + offsets)\n","    c = a + b\n","    tl.store(c_ptr + offsets, c)\n","\n","def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):\n","    grid = (1,)\n","    vector_add_kernel[grid](a, b, c)\n","\n","if __name__ == \"__main__\":\n","    N = 15 # <- the only line we edit\n","    a = torch.randn(N, device='cuda')\n","    b = torch.randn(N, device='cuda')\n","    torch_output = a + b\n","    triton_output = torch.empty_like(a)\n","    solve(a, b , triton_output, N)\n","    if torch.allclose(triton_output, torch_output):\n","        print(\"✅ Triton and Torch match\")\n","    else:\n","        print(\"❌ Triton and Torch differ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLUUqNUz2bQv","executionInfo":{"status":"ok","timestamp":1760682438074,"user_tz":300,"elapsed":84,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}},"outputId":"57813e55-0215-4f34-e66f-fcf567149e0c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Triton and Torch match\n"]}]},{"cell_type":"code","source":["\"\"\" WARNING: FOLLOWING CODE SAMPLE DEMONSTRATES A WRONG PATTERN\"\"\"\n","import torch\n","import triton\n","import triton.language as tl\n","\n","@triton.jit\n","def vector_add_kernel(a_ptr, b_ptr, c_ptr):\n","    offsets = tl.arange(0, 15) # <- the line we edit\n","    a = tl.load(a_ptr + offsets)\n","    b = tl.load(b_ptr + offsets)\n","    c = a + b\n","    tl.store(c_ptr + offsets, c)\n","\n","def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):\n","    grid = (1,)\n","    vector_add_kernel[grid](a, b, c)\n","\n","if __name__ == \"__main__\":\n","    N = 15 # <- the line we edit\n","    a = torch.randn(N, device='cuda')\n","    b = torch.randn(N, device='cuda')\n","    torch_output = a + b\n","    triton_output = torch.empty_like(a)\n","    solve(a, b , triton_output, N)\n","    if torch.allclose(triton_output, torch_output):\n","        print(\"✅ Triton and Torch match\")\n","    else:\n","        print(\"❌ Triton and Torch differ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":525},"id":"VjLvTx6i2exl","executionInfo":{"status":"error","timestamp":1760682446450,"user_tz":300,"elapsed":76,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}},"outputId":"3eff3576-fab7-4e4d-a38c-efab4a6b5cb8"},"execution_count":23,"outputs":[{"output_type":"error","ename":"CompilationError","evalue":"at 2:14:\ndef vector_add_kernel(a_ptr, b_ptr, c_ptr):\n    offsets = tl.arange(0, 15) # <- the line we edit\n              ^","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/language/core.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                              \"(`_semantic` argument must be provided outside of JIT functions.)\")\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/language/core.py\u001b[0m in \u001b[0;36marange\u001b[0;34m(start, end, _semantic)\u001b[0m\n\u001b[1;32m   1653\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unwrap_if_constexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_semantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/language/semantic.py\u001b[0m in \u001b[0;36marange\u001b[0;34m(self, start, end, ret_ty)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arange's range must be a power of 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: arange's range must be a power of 2","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mCompilationError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2533690700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtorch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtriton_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtriton_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriton_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Triton and Torch match\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2533690700.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b, c, N)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mvector_add_kernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mmemorizes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \"\"\"\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;31m# return cast(T, functools.partial(cast(Callable, self.run), grid=grid))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, grid, warmup, *args, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;31m# compile the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASTSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstexprs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m             \u001b[0mkernel_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             self._call_hook(knobs.runtime.jit_post_compile_hook, key, signature, device, constexprs, options, [attrs],\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(src, target, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mmodule_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_module_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodegen_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mfilter_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py\u001b[0m in \u001b[0;36mmake_ir\u001b[0;34m(self, options, codegen_fns, module_map, context)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodegen_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcode_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mast_to_ttir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\n\u001b[0m\u001b[1;32m     84\u001b[0m                            module_map=module_map)\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCompilationError\u001b[0m: at 2:14:\ndef vector_add_kernel(a_ptr, b_ptr, c_ptr):\n    offsets = tl.arange(0, 15) # <- the line we edit\n              ^"]}]},{"cell_type":"code","source":["import torch\n","import triton\n","import triton.language as tl\n","\n","@triton.jit\n","def vector_add_kernel(a_ptr, b_ptr, c_ptr, N):\n","    offsets = tl.arange(0, 16)\n","\n","    mask = offsets < N # size of your input vector\n","\n","    a = tl.load(a_ptr + offsets, mask=mask)\n","    b = tl.load(b_ptr + offsets, mask=mask)\n","    c = a + b\n","    tl.store(c_ptr + offsets, c, mask=mask)\n","\n","def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):\n","    grid = (1,)\n","    vector_add_kernel[grid](a, b, c, N)\n","\n","if __name__ == \"__main__\":\n","    for N in range(1, 16+1):\n","        a = torch.randn(N, device='cuda')\n","        b = torch.randn(N, device='cuda')\n","        torch_output = a + b\n","        triton_output = torch.empty_like(a)\n","        solve(a, b , triton_output, N)\n","        if torch.allclose(triton_output, torch_output):\n","            print(\"✅ Triton and Torch match\")\n","        else:\n","            print(\"❌ Triton and Torch differ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCG5lKrR2g0k","executionInfo":{"status":"ok","timestamp":1760682469724,"user_tz":300,"elapsed":473,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}},"outputId":"53b611c1-9041-46b0-afe3-cadcb67e8729"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n","✅ Triton and Torch match\n"]}]},{"cell_type":"code","source":["import time\n","import torch\n","import triton\n","import triton.language as tl\n","\n","@triton.jit\n","def vector_add_kernel(a_ptr, b_ptr, c_ptr, N):\n","\n","    pid = tl.program_id(axis=0) # pid is a unique ID for each Thread Block\n","\n","    block_start = pid * 16 # slicing data for each block\n","\n","    offsets = block_start + tl.arange(0, 16)\n","    mask = offsets < N\n","    a = tl.load(a_ptr + offsets, mask=mask)\n","    b = tl.load(b_ptr + offsets, mask=mask)\n","    c = a + b\n","    tl.store(c_ptr + offsets, c, mask=mask)\n","\n","def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):\n","    grid = (triton.cdiv(N, 16), )\n","    vector_add_kernel[grid](a, b, c, N)\n","\n","\n","def time_op_gpu(fn, sync=True, warmup=5, iters=20):\n","    \"\"\"\n","    Time a GPU operation using CUDA events for better accuracy (no CPU scheduling noise).\n","    - fn: a callable that launches GPU work\n","    - sync: whether to synchronize after each iteration (True recommended)\n","    - warmup: warm-up iterations to let JIT/caches settle\n","    - iters: timed iterations\n","\n","    Returns: average time in milliseconds over 'iters' runs.\n","    \"\"\"\n","    # warm-up does JIT and warms caches\n","    for _ in range(warmup):\n","        fn()\n","    if sync:\n","        torch.cuda.synchronize()\n","\n","    start = torch.cuda.Event(enable_timing=True)\n","    end = torch.cuda.Event(enable_timing=True)\n","    elapsed_ms = 0.0\n","    for _ in range(iters):\n","        start.record()\n","        fn()\n","        end.record()\n","        # Wait for the events to be recorded & measure GPU time\n","        torch.cuda.synchronize()\n","        elapsed_ms += start.elapsed_time(end)\n","    return elapsed_ms / iters\n","\n","if __name__ == \"__main__\":\n","    for power in range(1, 25 ,2):\n","        N = 2 ** power\n","        N = 1 << 24\n","        a = torch.randn(N, device='cuda')\n","        b = torch.randn(N, device='cuda')\n","        triton_output = torch.empty_like(a)\n","\n","        def torch_op():\n","            return a + b\n","\n","        def triton_op():\n","            triton_output = torch.empty_like(a)\n","            solve(a, b, triton_output, N)\n","            return triton_output\n","\n","        torch_output = torch_op()  # warm-up\n","        torch_time_elapsed = time_op_gpu(torch_op)\n","\n","        triton_output = triton_op()  # warm-up\n","        triton_time_elapsed = time_op_gpu(triton_op)\n","\n","        if torch.allclose(triton_output, torch_output):\n","            print(f\"✅ Triton and Torch match with input size 2^{power}\")\n","            print(f\"Torch  time: {torch_time_elapsed:.5f} ms, \\nTriton time: {triton_time_elapsed:.5f} ms\")\n","        else:\n","            print(f\"❌ Triton and Torch differ with input size 2^{power}\")\n","\n","        print(\"grid size: \", triton.cdiv(N, 16), \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPuKSu4V2mZ_","executionInfo":{"status":"ok","timestamp":1760682591687,"user_tz":300,"elapsed":1670,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}},"outputId":"3452ff08-d6ba-44d4-efe8-43f705531c79"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Triton and Torch match with input size 2^1\n","Torch  time: 1.33550 ms, \n","Triton time: 4.31417 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^3\n","Torch  time: 1.61238 ms, \n","Triton time: 3.68864 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^5\n","Torch  time: 1.14208 ms, \n","Triton time: 3.15389 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^7\n","Torch  time: 1.25037 ms, \n","Triton time: 2.98867 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^9\n","Torch  time: 1.57355 ms, \n","Triton time: 2.96891 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^11\n","Torch  time: 1.12892 ms, \n","Triton time: 2.86296 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^13\n","Torch  time: 1.80937 ms, \n","Triton time: 3.51826 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^15\n","Torch  time: 1.25404 ms, \n","Triton time: 2.88556 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^17\n","Torch  time: 1.35573 ms, \n","Triton time: 2.77837 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^19\n","Torch  time: 1.52062 ms, \n","Triton time: 2.86905 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^21\n","Torch  time: 1.27100 ms, \n","Triton time: 2.63440 ms\n","grid size:  1048576 \n","\n","✅ Triton and Torch match with input size 2^23\n","Torch  time: 1.25251 ms, \n","Triton time: 3.44298 ms\n","grid size:  1048576 \n","\n"]}]},{"cell_type":"code","source":["import time\n","import torch\n","import triton\n","import triton.language as tl\n","\n","@triton.jit\n","def vector_add_kernel(a_ptr, b_ptr, c_ptr, N, BLOCK: tl.constexpr):\n","\n","    pid = tl.program_id(axis=0) # pid is a unique ID for each Thread Block\n","\n","    # block_start = pid * 16 # slicing data for each block\n","    # offsets = block_start + tl.arange(0, 16)\n","\n","    offsets = pid * BLOCK + tl.arange(0, BLOCK)\n","\n","    mask = offsets < N\n","    a = tl.load(a_ptr + offsets, mask=mask)\n","    b = tl.load(b_ptr + offsets, mask=mask)\n","    c = a + b\n","    tl.store(c_ptr + offsets, c, mask=mask)\n","\n","def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, N: int):\n","    BLOCK = 1024\n","    grid = (triton.cdiv(N, BLOCK), )\n","    vector_add_kernel[grid](a, b, c, N, BLOCK=BLOCK, num_warps=4)\n","\n","\n","def time_op_gpu(fn, sync=True, warmup=5, iters=20):\n","    \"\"\"\n","    Time a GPU operation using CUDA events for better accuracy (no CPU scheduling noise).\n","    - fn: a callable that launches GPU work\n","    - sync: whether to synchronize after each iteration (True recommended)\n","    - warmup: warm-up iterations to let JIT/caches settle\n","    - iters: timed iterations\n","\n","    Returns: average time in milliseconds over 'iters' runs.\n","    \"\"\"\n","    # warm-up does JIT and warms caches\n","    for _ in range(warmup):\n","        fn()\n","    if sync:\n","        torch.cuda.synchronize()\n","\n","    start = torch.cuda.Event(enable_timing=True)\n","    end = torch.cuda.Event(enable_timing=True)\n","    elapsed_ms = 0.0\n","    for _ in range(iters):\n","        start.record()\n","        fn()\n","        end.record()\n","        # Wait for the events to be recorded & measure GPU time\n","        torch.cuda.synchronize()\n","        elapsed_ms += start.elapsed_time(end)\n","    return elapsed_ms / iters\n","\n","if __name__ == \"__main__\":\n","    for power in range(1, 25, 2):\n","        N = 2 ** power\n","        a = torch.randn(N, device='cuda')\n","        b = torch.randn(N, device='cuda')\n","        torch_output  = torch.empty_like(a)\n","        triton_output = torch.empty_like(a)\n","\n","        def torch_op():\n","            return torch_output.copy_(a + b)\n","\n","        def triton_op():\n","            triton_output = torch.empty_like(a)\n","            solve(a, b, triton_output, N)\n","            return triton_output\n","\n","        torch_output = torch_op()  # warm-up\n","        torch_time_elapsed = time_op_gpu(torch_op)\n","\n","        triton_output = triton_op()  # warm-up\n","        triton_time_elapsed = time_op_gpu(triton_op)\n","\n","        if torch.allclose(triton_output, torch_output):\n","            print(f\"✅ Triton and Torch match with input size 2^{power}\")\n","            print(f\"Torch  time: {torch_time_elapsed:.5f} ms, \\nTriton time: {triton_time_elapsed:.5f} ms\")\n","        else:\n","            print(f\"❌ Triton and Torch differ with input size 2^{power}\")\n","\n","        print(\"grid size: \", triton.cdiv(N, 16), \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2quNyzi2qrS","executionInfo":{"status":"ok","timestamp":1760682638427,"user_tz":300,"elapsed":257,"user":{"displayName":"tingxi li","userId":"07148518068737199447"}},"outputId":"df7ab327-5055-40ac-99b2-19147d69e141"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Triton and Torch match with input size 2^1\n","Torch  time: 0.17645 ms, \n","Triton time: 0.09037 ms\n","grid size:  1 \n","\n","✅ Triton and Torch match with input size 2^3\n","Torch  time: 0.04901 ms, \n","Triton time: 0.18940 ms\n","grid size:  1 \n","\n","✅ Triton and Torch match with input size 2^5\n","Torch  time: 0.31917 ms, \n","Triton time: 0.07534 ms\n","grid size:  2 \n","\n","✅ Triton and Torch match with input size 2^7\n","Torch  time: 0.34054 ms, \n","Triton time: 0.06917 ms\n","grid size:  8 \n","\n","✅ Triton and Torch match with input size 2^9\n","Torch  time: 0.04664 ms, \n","Triton time: 0.19412 ms\n","grid size:  32 \n","\n","✅ Triton and Torch match with input size 2^11\n","Torch  time: 0.07051 ms, \n","Triton time: 0.06189 ms\n","grid size:  128 \n","\n","✅ Triton and Torch match with input size 2^13\n","Torch  time: 0.23926 ms, \n","Triton time: 0.08479 ms\n","grid size:  512 \n","\n","✅ Triton and Torch match with input size 2^15\n","Torch  time: 0.07361 ms, \n","Triton time: 0.07344 ms\n","grid size:  2048 \n","\n","✅ Triton and Torch match with input size 2^17\n","Torch  time: 0.05223 ms, \n","Triton time: 0.06151 ms\n","grid size:  8192 \n","\n","✅ Triton and Torch match with input size 2^19\n","Torch  time: 0.25605 ms, \n","Triton time: 0.08298 ms\n","grid size:  32768 \n","\n","✅ Triton and Torch match with input size 2^21\n","Torch  time: 0.76483 ms, \n","Triton time: 0.46037 ms\n","grid size:  131072 \n","\n","✅ Triton and Torch match with input size 2^23\n","Torch  time: 1.53014 ms, \n","Triton time: 0.63391 ms\n","grid size:  524288 \n","\n"]}]}]}